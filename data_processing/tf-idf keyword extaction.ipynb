{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading brown: <urlopen error [Errno 61] Connection\n",
      "[nltk_data]     refused>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 61] Connection refused>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import string\n",
    "from rake_nltk import Rake\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os, json\n",
    "import pandas.io.json as pd_json\n",
    "from eda import *\n",
    "from words_refine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "#     results= {}\n",
    "#     for idx in range(len(feature_vals)):\n",
    "#         results[feature_vals[idx]]=score_vals[idx]\n",
    "    results = []\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results.append(feature_vals[idx])\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_json1(filename):\n",
    "    data_list = []\n",
    "    lines = open(filename,'r').readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line = json.loads(lines[i])\n",
    "        \n",
    "        # refine origins\n",
    "        tmp_origin = line['origins'] if line['origins'] else None\n",
    "        tmp_origin = tmp_origin if tmp_origin is None else tmp_origin[0]\n",
    "        \n",
    "        # refine ingredients\n",
    "        tmp_ingredients = line['ingredients'] if line['ingredients'] else None\n",
    "        tmp_ingredients = tmp_ingredients['ingredients'] if tmp_ingredients is not None else tmp_ingredients\n",
    "        tmp_ingredients = tmp_ingredients if tmp_ingredients else None\n",
    "        # merge to one sentences\n",
    "        tmp_ingredients = \", \".join(tmp_ingredients) if tmp_ingredients is not None else None\n",
    "        \n",
    "        # refine allergens\n",
    "        tmp_allergens =  line['allergens'] if line['allergens'] else None\n",
    "        # merge to one sentences\n",
    "        tmp_allergens = \", \".join(tmp_allergens) if tmp_allergens is not None else None\n",
    "        \n",
    "        tmp_description = line['description'] if line['description'] else None\n",
    "        \n",
    "        # \n",
    "        if line['breadcrumb'] is None:\n",
    "            dic = {'name':line['name'], 'description': tmp_description,'origins':tmp_origin,\n",
    "                   'allergens':tmp_allergens,'ingredients':tmp_ingredients,\n",
    "                  'salePrice':line['price']['salePrice'],'savePrice':line['price']['savePrice'],\n",
    "                  'label_1': None,\n",
    "                  'label_2': None,\n",
    "                  'label_3': None,\n",
    "                  'tf-idf' : []}            \n",
    "        else:\n",
    "            dic = {'name':line['name'], 'description': tmp_description,'origins':tmp_origin,\n",
    "                   'allergens':tmp_allergens,'ingredients':tmp_ingredients,\n",
    "                  'salePrice':line['price']['salePrice'],'savePrice':line['price']['savePrice'],\n",
    "                  'label_1':line['breadcrumb']['department']['name'],\n",
    "                  'label_2':line['breadcrumb']['aisle']['name'],\n",
    "                  'label_3': line['breadcrumb']['shelf']['name'],\n",
    "                  'tf-idf' : []}\n",
    "        data_list.append(dic)\n",
    "    #json_data = json.dumps(data)\n",
    "    df = pd.DataFrame.from_dict(data_list)\n",
    "    return df\n",
    "\n",
    "# load json with eda\n",
    "def load_json2(filename):\n",
    "    data_list = []\n",
    "    lines = open(filename,'r').readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line = json.loads(lines[i])\n",
    "        \n",
    "        # refine origins\n",
    "        tmp_origin = line['origins'] if line['origins'] else None\n",
    "        tmp_origin = tmp_origin if tmp_origin is None else tmp_origin[0]\n",
    "        \n",
    "        # refine ingredients\n",
    "        tmp_ingredients = line['ingredients'] if line['ingredients'] else None\n",
    "        tmp_ingredients = tmp_ingredients['ingredients'] if tmp_ingredients is not None else tmp_ingredients\n",
    "        tmp_ingredients = tmp_ingredients if tmp_ingredients else None\n",
    "        # merge to one sentences\n",
    "        tmp_ingredients = \", \".join(tmp_ingredients) if tmp_ingredients is not None else None\n",
    "        \n",
    "        # refine allergens\n",
    "        tmp_allergens =  line['allergens'] if line['allergens'] else None\n",
    "        # merge to one sentences\n",
    "        tmp_allergens = \", \".join(tmp_allergens) if tmp_allergens is not None else None\n",
    "        \n",
    "        # EDA for description and ingredient\n",
    "        tmp_description = line['description'] if line['description'] else None\n",
    "        alpha = 0.1\n",
    "        #print (i)\n",
    "        if tmp_description is not None:\n",
    "            tmp_description = eda(tmp_description, alpha_sr=alpha, alpha_ri=alpha,\n",
    "                                  alpha_rs=alpha, p_rd=alpha, num_aug=9)\n",
    "            tmp_description = \". \".join(tmp_description)\n",
    "        if tmp_ingredients is not None:\n",
    "            tmp_ingredients = eda(tmp_ingredients, alpha_sr=alpha, alpha_ri=alpha,\n",
    "                                  alpha_rs=alpha, p_rd=alpha, num_aug=9)\n",
    "            tmp_ingredients = \". \".join(tmp_ingredients)\n",
    "        \n",
    "        # \n",
    "        if line['breadcrumb'] is None:\n",
    "            dic = {'name':line['name'], 'description': tmp_description,'origins':tmp_origin,\n",
    "                   'allergens':tmp_allergens,'ingredients':tmp_ingredients,\n",
    "                  'salePrice':line['price']['salePrice'],'savePrice':line['price']['savePrice'],\n",
    "                  'label_1': None,\n",
    "                  'label_2': None,\n",
    "                  'label_3': None,\n",
    "                  'tf-idf' : []}            \n",
    "        else:\n",
    "            dic = {'name':line['name'], 'description': tmp_description,'origins':tmp_origin,\n",
    "                   'allergens':tmp_allergens,'ingredients':tmp_ingredients,\n",
    "                  'salePrice':line['price']['salePrice'],'savePrice':line['price']['savePrice'],\n",
    "                  'label_1':line['breadcrumb']['department']['name'],\n",
    "                  'label_2':line['breadcrumb']['aisle']['name'],\n",
    "                  'label_3': line['breadcrumb']['shelf']['name'],\n",
    "                  'tf-idf' : []}\n",
    "        data_list.append(dic)\n",
    "    #json_data = json.dumps(data)\n",
    "    df = pd.DataFrame.from_dict(data_list)\n",
    "    return df\n",
    "\n",
    "def add_keyword(data):\n",
    "    tmp = data[\"description\"].dropna()\n",
    "    cv=CountVectorizer(stop_words='english')\n",
    "    word_count_vector=cv.fit_transform(tmp)\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    \n",
    "    feature_names=cv.get_feature_names()\n",
    "    for i in range(data.shape[0]):\n",
    "        des = data.iloc[i]['description']\n",
    "        if des is not None:\n",
    "            tf_idf_vector=tfidf_transformer.transform(cv.transform([des]))\n",
    "            sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "            keywords=extract_topn_from_vector(feature_names,sorted_items,5)\n",
    "            data.at[i,'tf-idf'] = keywords\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_df = load_json1('browse.json')\n",
    "special_df = load_json1('specials.json')\n",
    "# browse_df.to_csv('browse_df.csv', sep=',', header=True, index=True)\n",
    "# special_df.to_csv('special_df.csv', sep=',', header=True, index=True)\n",
    "br_eda_df = load_json2('browse.json')\n",
    "sp_eda_df = load_json2('specials.json')\n",
    "\n",
    "data = br_eda_df.append(sp_eda_df,ignore_index=True)\n",
    "data = add_keyword(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.to_csv('dataset.csv', sep=',', header=True, index=True)\n",
    "\n",
    "a = list(data['label_3'].unique())\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = data[\"description\"].dropna()\n",
    "# cv=CountVectorizer(stop_words='english')\n",
    "# word_count_vector=cv.fit_transform(tmp)\n",
    "# tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "# tfidf_transformer.fit(word_count_vector)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "\n",
    "# feature_names=cv.get_feature_names()\n",
    "# tf_idf_vector=tfidf_transformer.transform(cv.transform([tmp[0]]))\n",
    "# sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "# keywords=extract_topn_from_vector(feature_names,sorted_items,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipes = pd.read_csv('recipes.csv', sep=\",\", header=0)\n",
    "# recipes.drop('url',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
