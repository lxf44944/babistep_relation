{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/yue/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yue/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yue/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Basic NLP with NLTK\n",
    "from nltk.corpus import brown\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "with open(\"en.json\") as json_data:\n",
    "    en_json = json.load(json_data)\n",
    "\n",
    "stopwords_json_en = set(en_json)\n",
    "stopwords_nltk_en = set(stopwords.words('english'))\n",
    "stopwords_punct = set(punctuation)\n",
    "# Combine the stopwords. \n",
    "stoplist_combined = set.union(stopwords_json_en, stopwords_nltk_en, stopwords_punct)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv', index_col = 0)\n",
    "def rebuild(data):\n",
    "    data_list = []\n",
    "    for i in range(data.shape[0]):\n",
    "        name = data.at[i,'name']\n",
    "        desc = data.at[i,'description']\n",
    "        if type(desc) is float:\n",
    "            if type(data.at[i,'label_1']) is not float:\n",
    "                labels = data.at[i,'label_1'] + ' ' + data.at[i,'label_2'] + ' ' + data.at[i,'label_3']\n",
    "                desc = labels + ' ' + name\n",
    "            else:\n",
    "                desc = name\n",
    "        dic = {'name':name,'content': desc}\n",
    "        data_list.append(dic)\n",
    "    df = pd.DataFrame.from_dict(data_list)\n",
    "    return df\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "def lemmatize_sent(text): \n",
    "    # Text input is string, returns lowercased strings.\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(word_tokenize(text))]\n",
    "\n",
    "def to_count_vec(string):\n",
    "    # Input: str, i.e. document/sentence\n",
    "    # Output: list(str) , i.e. list of lemmas\n",
    "    analysis = [word for word in lemmatize_sent(string) \n",
    "       if word not in stoplist_combined\n",
    "       and not word.isdigit() ]\n",
    "    return analysis\n",
    "\n",
    "def my_cluster(dataframe, num = 100):\n",
    "    tmp = dataframe['content'].values.astype('U')\n",
    "    # from nltk import sent_tokenize, word_tokenize\n",
    "    # count_vect = CountVectorizer(stop_words=stoplist_combined, tokenizer=word_tokenize)\n",
    "    vectorizer = CountVectorizer(analyzer=to_count_vec)     # same as above\n",
    "    X = vectorizer.fit_transform(tmp)\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf = transformer.fit_transform(X)\n",
    "    \n",
    "    km = KMeans(n_clusters=num)\n",
    "    km.fit(tfidf)\n",
    "    clusters = km.labels_.tolist()\n",
    "#     answer={'answer_body':document, 'cluster':clusters} \n",
    "    frame=pd.DataFrame({'name':dataframe['name'],'content': tmp, 'cluster': clusters}, columns=['name','content','cluster'])\n",
    "    return frame.sort_values(by='cluster', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rebuild(data)\n",
    "g_frame = my_cluster(df,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17493</td>\n",
       "      <td>sea cuisine squid tubes frozen</td>\n",
       "      <td>Frozen Frozen Seafood Frozen Prawns &amp; Squid se...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15305</td>\n",
       "      <td>kiwi crush frozen fruit drink kiwi gold concen...</td>\n",
       "      <td>Frozen Frozen Fruit &amp; Drink Frozen Fruit Drink...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17450</td>\n",
       "      <td>magnum ice cream chocolate raspberry</td>\n",
       "      <td>Frozen Ice Cream &amp; Sorbet Tubs magnum ice crea...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18322</td>\n",
       "      <td>streets magnum mini ice cream double caramel e...</td>\n",
       "      <td>Frozen Ice Cream &amp; Sorbet Single Serve &amp; Multi...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18317</td>\n",
       "      <td>talleys corn cobs</td>\n",
       "      <td>Frozen Frozen Vegetables Frozen Peas, Corn &amp; C...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7445</td>\n",
       "      <td>clairol herbal essence conditioner normal</td>\n",
       "      <td>Health &amp; Beauty Hair Care Condition &amp; Shine cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8295</td>\n",
       "      <td>tresemme conditioner hydration boost</td>\n",
       "      <td>Health &amp; Beauty Hair Care Condition &amp; Shine tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8312</td>\n",
       "      <td>clairol herbal essence conditioner colour</td>\n",
       "      <td>Health &amp; Beauty Hair Care Condition &amp; Shine cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8723</td>\n",
       "      <td>tresemme conditioner keratin smooth</td>\n",
       "      <td>Health &amp; Beauty Hair Care Condition &amp; Shine tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8326</td>\n",
       "      <td>essano conditioner blonde</td>\n",
       "      <td>Health &amp; Beauty Hair Care Condition &amp; Shine es...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19711 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "17493                     sea cuisine squid tubes frozen   \n",
       "15305  kiwi crush frozen fruit drink kiwi gold concen...   \n",
       "17450               magnum ice cream chocolate raspberry   \n",
       "18322  streets magnum mini ice cream double caramel e...   \n",
       "18317                                  talleys corn cobs   \n",
       "...                                                  ...   \n",
       "7445           clairol herbal essence conditioner normal   \n",
       "8295                tresemme conditioner hydration boost   \n",
       "8312           clairol herbal essence conditioner colour   \n",
       "8723                 tresemme conditioner keratin smooth   \n",
       "8326                           essano conditioner blonde   \n",
       "\n",
       "                                                 content  cluster  \n",
       "17493  Frozen Frozen Seafood Frozen Prawns & Squid se...       99  \n",
       "15305  Frozen Frozen Fruit & Drink Frozen Fruit Drink...       99  \n",
       "17450  Frozen Ice Cream & Sorbet Tubs magnum ice crea...       99  \n",
       "18322  Frozen Ice Cream & Sorbet Single Serve & Multi...       99  \n",
       "18317  Frozen Frozen Vegetables Frozen Peas, Corn & C...       99  \n",
       "...                                                  ...      ...  \n",
       "7445   Health & Beauty Hair Care Condition & Shine cl...        0  \n",
       "8295   Health & Beauty Hair Care Condition & Shine tr...        0  \n",
       "8312   Health & Beauty Hair Care Condition & Shine cl...        0  \n",
       "8723   Health & Beauty Hair Care Condition & Shine tr...        0  \n",
       "8326   Health & Beauty Hair Care Condition & Shine es...        0  \n",
       "\n",
       "[19711 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
